{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Submission-Copy1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4EQ016W2YkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xG_SsP22eNV",
        "colab_type": "code",
        "outputId": "3c4ff582-530f-4d07-d872-c53b5b8f7960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!curl -L -o train.csv https://drive.google.com/uc?id=1qkQphSpb7CjBYtd_93wWgISfo2H3HOcT\n",
        "!curl -L -o test.csv https://drive.google.com/uc?id=1KstvnYRkkuBRI5AFE4Q-xeAVFmkp0haw"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   377    0   377    0     0    148      0 --:--:--  0:00:02 --:--:--   148\n",
            "100 72.7M    0 72.7M    0     0  17.7M      0 --:--:--  0:00:04 --:--:-- 53.8M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   377    0   377    0     0    325      0 --:--:--  0:00:01 --:--:--   325\n",
            "100 21.9M    0 21.9M    0     0  11.1M      0 --:--:--  0:00:01 --:--:-- 36.3M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY53L8-474SY",
        "colab_type": "code",
        "outputId": "956ca63b-bf52-486c-a546-9e0c0dd9fe63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!curl -L -o cc.ru.300.vec.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1245M  100 1245M    0     0  12.1M      0  0:01:42  0:01:42 --:--:-- 12.3M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owkwu9IA75L9",
        "colab_type": "code",
        "outputId": "f78dd749-3ca2-4d8c-a3dc-cd7adf3e4d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!gunzip cc.ru.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gzip: cc.ru.300.vec already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvXmaiMo774r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod +x cc.ru.300.vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Dhwr01KOera",
        "colab_type": "code",
        "outputId": "900e8c10-1b3a-4afc-8a27-0efe49011999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cc.ru.300.vec\t  sample_data\t    submission8.csv  test.csv\n",
            "cc.ru.300.vec.gz  submission10.csv  submission9.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkcathiO2YkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('./train.csv')\n",
        "test = pd.read_csv('./test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWvZIcrjO3qz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU6hz8D12YkX",
        "colab_type": "code",
        "outputId": "5e5af599-f86f-47f0-8b99-b921f6876462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>main_category</th>\n",
              "      <th>sub_category</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>Законно ли изменение количества дней листа нет...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>Погадайте что будут, у меня предчувствия?) К ч...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>66</td>\n",
              "      <td>Какой дровокол надёжней?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>45</td>\n",
              "      <td>Зачем в старой Японии женщины бинтовали грудь ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>47</td>\n",
              "      <td>Положив руку.. на ...ну что там у вас, мужчин</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   main_category  ...                                           question\n",
              "0              4  ...  Законно ли изменение количества дней листа нет...\n",
              "1              1  ...  Погадайте что будут, у меня предчувствия?) К ч...\n",
              "2             10  ...                           Какой дровокол надёжней?\n",
              "3              6  ...  Зачем в старой Японии женщины бинтовали грудь ...\n",
              "4              6  ...      Положив руку.. на ...ну что там у вас, мужчин\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRU50ie42Yka",
        "colab_type": "code",
        "outputId": "43e6ec6a-3094-461e-aa13-636256075da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlDzR4UA2Ykd",
        "colab_type": "code",
        "outputId": "afeac8b4-3d9e-40b7-cd8a-529966aa0895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "train.main_category.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20    42737\n",
              "4     38047\n",
              "3     37550\n",
              "10    33813\n",
              "16    31015\n",
              "0     29520\n",
              "13    28071\n",
              "6     27146\n",
              "19    26563\n",
              "2     26455\n",
              "18    25388\n",
              "14    25266\n",
              "12    23407\n",
              "5     23394\n",
              "7     23150\n",
              "1     23051\n",
              "27    22921\n",
              "17    22215\n",
              "24    22138\n",
              "8     19958\n",
              "22    18965\n",
              "26    16226\n",
              "11    15771\n",
              "15    15491\n",
              "25    15488\n",
              "21    11846\n",
              "9     11413\n",
              "23     9661\n",
              "Name: main_category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BukTZQN_2Ykf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AhiyKVz2Ykh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_text(text):\n",
        "    \n",
        "    words = wordpunct_tokenize(text.lower())\n",
        "    \n",
        "    return words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiGvmGkx2Ykj",
        "colab_type": "code",
        "outputId": "40e79c2e-3297-44c2-fb23-11cf06d31f35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2freq = {}\n",
        "\n",
        "for question in tqdm(train.question):\n",
        "    \n",
        "    words = process_text(question)\n",
        "    \n",
        "    for word in words:\n",
        "        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 666666/666666 [00:06<00:00, 106642.30it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZoi5zCJ2Ykl",
        "colab_type": "code",
        "outputId": "bfedd440-280b-4845-b5fa-4ffb2bdf0be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [02:00<00:00, 16604.90it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf_0tfgb2Ykn",
        "colab_type": "code",
        "outputId": "78785a6b-1946-46c8-c4b3-e3d113fc9b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Мы не знаем 3.02 % слов в датасете\n",
            "Количество неизвестных слов 107889 из 328896, то есть 32.80 % уникальных слов в словаре\n",
            "В среднем каждое встречается 2.08 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 8604\n",
            "!!! с количеством вхождениий - 6976\n",
            "?) с количеством вхождениий - 6613\n",
            "?? с количеством вхождениий - 6327\n",
            "\"? с количеством вхождениий - 4581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Z6HZu32Ykp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, z_data, word2index, sequence_length=64, pad_token='PAD', verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "        self.z_data = z_data\n",
        "        \n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "        \n",
        "        self.load(x_data, verbose=verbose)\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "    \n",
        "        words = wordpunct_tokenize(text.lower())\n",
        "\n",
        "        return words\n",
        "        \n",
        "    def load(self, data, verbose=True):\n",
        "        \n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "        for text in data_iterator:\n",
        "            words = self.process_text(text)\n",
        "            indexed_words = self.indexing(words)\n",
        "            self.x_data.append(indexed_words)\n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        return [self.word2index[token] for token in tokenized_text if token in self.word2index ]\n",
        "    \n",
        "    def padding(self, sequence):\n",
        "\n",
        "        if len(sequence) > self.sequence_length:\n",
        "            sequence = sequence[:self.sequence_length]\n",
        "        elif len(sequence) < self.sequence_length:\n",
        "            sequence = sequence + [self.pad_index] * (self.sequence_length - len(sequence))\n",
        "\n",
        "        return sequence\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        z = self.z_data[idx]\n",
        "        \n",
        "        return x, y, z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAo7wgBQ2Ykq",
        "colab_type": "code",
        "outputId": "a423ad5d-c12b-4384-ac70-645280c1301e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(train.question, train.main_category, test_size=0.1)\n",
        "z_train = train.sub_category[y_train.index]\n",
        "z_validation = train.sub_category[y_validation.index]\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), list(z_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), list(z_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)\n",
        "\n",
        "test_dataset = WordData(list(test.question), np.zeros((test.shape[0])), np.zeros((test.shape[0])), word2index)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data: 100%|██████████| 599999/599999 [00:07<00:00, 81968.76it/s] \n",
            "Loading data: 100%|██████████| 66667/66667 [00:00<00:00, 99059.11it/s] \n",
            "Loading data: 100%|██████████| 200000/200000 [00:02<00:00, 88280.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzQ2Z3Vk2Yks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x, y, z in test_loader:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvl-SfA02Yku",
        "colab_type": "code",
        "outputId": "5aa1ac7e-8a8d-412b-c74c-c06e6110d1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQwuAiQn2Ykw",
        "colab_type": "code",
        "outputId": "d22fc1ec-f70c-434b-c4ea-e4fc655e76a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIlKGF0E2Yky",
        "colab_type": "code",
        "outputId": "cfddc3c1-7e01-4b02-e5a0-8da464cbb49b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "z"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W2U5jqy2Ykz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main_classes = train.main_category.unique().shape[0]\n",
        "sub_classes = train.sub_category.unique().shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H2uv-zqn8UZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnlm8qRX2Yk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepAverageNetwork(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, embedding_matrix, n_classes_main, n_classes_sub):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "\n",
        "        self.filter_sizes = [1,2,3,5,6,7,8,9,10]\n",
        "        self.num_filters = 512\n",
        "        self.embedding_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(embedding_matrix))\n",
        "        self.lstm = torch.nn.LSTM(300, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
        "        self.convs1 = torch.nn.ModuleList([torch.nn.Conv1d(256, self.num_filters, K) for K in self.filter_sizes])\n",
        "        self.convs2 = torch.nn.ModuleList([torch.nn.Conv1d(512, self.num_filters, K) for K in self.filter_sizes[:4]])\n",
        "        self.layers = torch.nn.Sequential(torch.nn.ReLU(),\n",
        "                                  torch.nn.Dropout(0.2),\n",
        "                                  torch.nn.Linear(256, 128),\n",
        "                                  torch.nn.ReLU(),\n",
        "                                  torch.nn.Dropout(0.2))\n",
        "        self.layers2 = torch.nn.Sequential(torch.nn.ReLU(),\n",
        "                                  torch.nn.Dropout(0.2),\n",
        "                                  torch.nn.Linear(self.num_filters*len(self.filter_sizes), 128),\n",
        "                                  torch.nn.ReLU(),\n",
        "                                  torch.nn.Dropout(0.2))\n",
        "        self.linear_main = torch.nn.Linear(128, n_classes_main)\n",
        "        self.linear_sub = torch.nn.Linear(128, n_classes_sub)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        sequence_lengths = (x > 0).sum(dim=1)\n",
        "        sequence_lengths[sequence_lengths == 0.] = 1\n",
        "        \n",
        "        x = self.embedding_layer(x)\n",
        "        \n",
        "        x, hidden = self.lstm(x)\n",
        "\n",
        "        x= [F.relu(conv(x.transpose(1,2))) for conv in self.convs1]\n",
        "\n",
        "        \n",
        "        x= [F.max_pool1d(i, i.size(2)).squeeze() for i in x] \n",
        "        x = torch.cat(x, 1)\n",
        "\n",
        "        x = self.layers2(x)\n",
        "        x1 = self.linear_main(x)\n",
        "        x2 = self.linear_sub(x)\n",
        "        \n",
        "        return x1, x2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcARENt52Yk5",
        "colab_type": "code",
        "outputId": "d3bcf6bd-e0ba-4c35-ab90-52c9fae454b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = DeepAverageNetwork(embedding_matrix=vectors, n_classes_main=main_classes, n_classes_sub=sub_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch 1:  95%|█████████▍| 568704/599999 [08:10<00:25, 1222.84it/s, train_loss=2.29]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm0BdGEY2Yk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    pred1, pred2 = model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbV-ITO52Yk-",
        "colab_type": "code",
        "outputId": "2027547f-00b7-4bc6-b5aa-07b368ec3212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i4E4LsG2YlB",
        "colab_type": "code",
        "outputId": "300981bf-5b3f-42d6-8f3f-a20ea7d26717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred2.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 209])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkVuTyvS2YlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCsgd9oiV7dv",
        "colab_type": "code",
        "outputId": "9641f20c-1e2f-4807-9af4-75a636bb0797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKIVyr832YlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's make a weighted training\n",
        "\n",
        "def get_weights(label):\n",
        "        lab2id = lab2id = {x: i for i, x in enumerate(sorted(set(train[label][i].item() for i in range(train[label].shape[0]))))}\n",
        "        weights = torch.FloatTensor([\n",
        "                    1.0 / (train[label] == i).sum().item()\n",
        "                    for i in range(len(lab2id))\n",
        "                ]).to(device)\n",
        "        weights = weights / weights.sum()\n",
        "        return weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "finvSYmH2YlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLfih-1y2YlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "# criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MET1mjGOGBpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_main = get_weights('main_category')\n",
        "weights_sub = get_weights('sub_category')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLTWJLLq2YlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    early_stoping_value = 0\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y, z in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        z = z.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred1, pred2 = model(x)\n",
        "        loss1 = F.cross_entropy(pred1, y, weight=weights_main) #criterion(pred, y)\n",
        "        loss2 = F.cross_entropy(pred2, z, weight=weights_sub)\n",
        "        \n",
        "        loss = (loss1 + loss2)/2\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y, z in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        z = z.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred1, pred2 = model(x)\n",
        "\n",
        "            pred1 = pred1.cpu()\n",
        "            pred2 = pred2.cpu()\n",
        "            y = y.cpu()\n",
        "            z = z.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred1, axis=1))\n",
        "\n",
        "            loss = F.cross_entropy(pred1, y) #criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "    \n",
        "    \n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "        early_stoping_value=0\n",
        "    else:\n",
        "        early_stoping_value+=1\n",
        "        if early_stoping_value>=2:\n",
        "            print('Early stopping')\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVG2oxTp2YlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccf0HRcc2YlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for x, _, __ in test_loader:\n",
        "\n",
        "    x = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        pred1, pred2 = model(x)\n",
        "\n",
        "        pred1 = pred1.cpu()\n",
        "        \n",
        "        predictions.append(np.argmax(pred1, axis=1))\n",
        "        \n",
        "predictions = np.concatenate(predictions).squeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIOkPRBG2YlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_aRiiwI2YlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['main_category'] = predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUeCXUBq2YlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test[['index', 'main_category']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDGOV31W2YlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybQXZrcI2YlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3bpan9J2YlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.to_csv('submission11.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LrPPk0e2YlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('submission11.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}